{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_type, cm, target_names, title, cmap=None, normalize=True):\n",
    "    \"\"\"\n",
    "    link: https://www.kaggle.com/grfiv4/plot-a-confusion-matrix \n",
    "    Given a sklearn confusion matrix (cm), make a confusion matrix plot\n",
    "    \"\"\"\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\n\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    filename = './'+ model_type + '/'+ model_type + '_confusion_matrix.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_graphs(emotion_keys, true_counts, pred_counts, model_type):\n",
    "    \"\"\"\n",
    "    Given emotion keys, true labels, predicted labels, create and save distribution bar plots.\n",
    "    \"\"\"\n",
    "    index = np.arange(len(emotion_keys))\n",
    "    \n",
    "    # Only true labels\n",
    "    plt.bar(index, true_counts)\n",
    "    plt.xticks(index, emotion_keys)\n",
    "    plt.ylabel('Count')\n",
    "    plt.ylim(0, 800)\n",
    "    plt.title('True Labels by Emotion')\n",
    "    filename = './'+ model_type + '/'+ model_type + '_true_labels_bar.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "    # Only predicted labels\n",
    "    plt.bar(index, pred_counts)\n",
    "    plt.xticks(index, emotion_keys)\n",
    "    plt.ylabel('Count')\n",
    "    plt.ylim(0, 800)\n",
    "    plt.title('Predicted Labels by Emotion')\n",
    "    filename = './'+ model_type + '/'+ model_type + '_predicted_labels_bar.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "    # Both labels\n",
    "    fig, ax = plt.subplots()\n",
    "    bar_width = 0.35\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, true_counts, bar_width, alpha=opacity, color='b', label='True Labels')\n",
    "    rects2 = plt.bar(index + bar_width, pred_counts, bar_width, alpha=opacity, color='g', label='Predicted Labels')\n",
    "\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('True Labels and Predicted Labels')\n",
    "    plt.xticks(index + bar_width / 2, emotion_keys)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = './'+ model_type + '/'+ model_type + '_both_labels_bar.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(labels, predictions, emotion_keys, model_type):\n",
    "    matrix = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    true_counts = np.zeros((len(emotion_keys)))\n",
    "    pred_counts = np.zeros((len(emotion_keys)))\n",
    "    \n",
    "    for val in range(len(emotion_keys)):\n",
    "        true_counts[val] = np.count_nonzero(labels == val)\n",
    "        pred_counts[val] = np.count_nonzero(predictions == val)\n",
    "    \n",
    "    plot_confusion_matrix(model_type   = model_type,\n",
    "                          cm           = matrix,\n",
    "                          normalize    = True,\n",
    "                          target_names = emotion_keys,\n",
    "                          title        = \"Confusion Matrix\")\n",
    "    \n",
    "    plot_bar_graphs(emotion_keys, true_counts, pred_counts, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_keys = ['angry', 'disgust', 'fear', 'happy', 'sad', 'suprise', 'neutral']\n",
    "kaggle_labels = np.load('./labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4880603267700042"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: Alexnet, lr=0.005\n",
    "model_type = 'alexnet_lr_005'\n",
    "alexnet_pred = np.load('./alexnet_kaggle/test_predictions.npy')\n",
    "create_plots(kaggle_labels, alexnet_pred, emotion_keys, model_type)\n",
    "accuracy_score(kaggle_labels, alexnet_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: VGG-11, lr=0.005\n",
    "model_type = 'vgg_11_lr_005'\n",
    "vgg_pred = np.load('./vgg_kaggle/test_predictions.npy')\n",
    "create_plots(kaggle_labels, vgg_pred, emotion_keys, model_type)\n",
    "accuracy_score(kaggle_labels, vgg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5881860075408463"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: VGG-19, lr=0.01\n",
    "model_type = 'vgg_11_lr_01'\n",
    "vgg_pred_2 = np.load('./vgg_kaggle_2/test_predictions.npy')\n",
    "create_plots(kaggle_labels, vgg_pred_2, emotion_keys, model_type)\n",
    "accuracy_score(kaggle_labels, vgg_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4905739421868454"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: Resnet-18, lr=0.005\n",
    "model_type = 'resnet_18_lr_005'\n",
    "resnet_pred = np.load('./resnet_kaggle/test_predictions.npy')\n",
    "create_plots(kaggle_labels, resnet_pred, emotion_keys, model_type)\n",
    "accuracy_score(kaggle_labels, resnet_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4503560955173858"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: Densenet-121, lr=0.001\n",
    "model_type = 'densenet_121_lr_001'\n",
    "densenet_pred = np.load('./densenet_kaggle/test_predictions.npy')\n",
    "create_plots(kaggle_labels, densenet_pred, emotion_keys, model_type)\n",
    "accuracy_score(kaggle_labels, densenet_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4968579807289485"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: Densenet-121, lr=0.0025\n",
    "model_type = 'densenet_121_lr_0025'\n",
    "densenet_pred_2 = np.load('./densenet_kaggle_2/test_predictions.npy')\n",
    "create_plots(kaggle_labels, densenet_pred_2, emotion_keys, model_type)\n",
    "accuracy_score(kaggle_labels, densenet_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.553414327607876"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: Densenet-121, lr=0.01\n",
    "model_type = 'densenet_121_lr_01'\n",
    "densenet_pred_3 = np.load('./densenet_kaggle_3/test_predictions.npy')\n",
    "create_plots(kaggle_labels, densenet_pred_3, emotion_keys, model_type)\n",
    "accuracy_score(kaggle_labels, densenet_pred_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
